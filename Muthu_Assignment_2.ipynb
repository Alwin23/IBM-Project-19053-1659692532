{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "wjVE9l-v1U6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35k3C5vm1RFz"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir =\"https://drive.google.com/file/d/1xkynpL15pt6KT3YSlDimu4A5iRU9qYck/view\""
      ],
      "metadata": {
        "id": "Fpq8Zq1o1fd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = torchvision.transforms.Compose(\n",
        "    [  # Applying Augmentation\n",
        "        torchvision.transforms.Resize((224, 224)),\n",
        "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
        "        torchvision.transforms.RandomRotation(40),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "database = ImageFolder(data_dir, transform=transformer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "iJGDGwmG2Eb4",
        "outputId": "bcc5fddc-9e4e-4e37-b3b6-d5b882d43261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-97c8b8fc8d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "GJc6mrm32P1y",
        "outputId": "69f5930d-cf89-4ae0-c660-effbd8fc4b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a46250781e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'database' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flower_label = {\n",
        "    0: 'daisy',\n",
        "    1: 'dandelion',\n",
        "    2: 'rose',\n",
        "    3: 'sunflower',\n",
        "    4: 'tulip'\n",
        "}"
      ],
      "metadata": {
        "id": "xJM2hyVN2cJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(dl,invert=True):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break\n",
        "\n",
        "def show_sample(image, label,invert=True):\n",
        "    print(\"Label :\" +database.classes[label] + \"(\" + str(label) + \")\")\n",
        "    plt.imshow(image.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "qx2dNTNY2dEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_sample(*database[1])"
      ],
      "metadata": {
        "id": "TjrrnDYo2jk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_size = 500\n",
        "training_size = len(database) - validation_size"
      ],
      "metadata": {
        "id": "ANRsnCwA2kei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds_main = random_split(database,[training_size, validation_size])\n",
        "val_ds, test_ds  = random_split(val_ds_main,[300, 200])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "dUARc7mA2m06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32"
      ],
      "metadata": {
        "id": "ZVDvi_sN2rUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size , shuffle=True)\n",
        "val_dl = DataLoader(val_ds,batch_size)\n",
        "test_dl = DataLoader(test_ds, batch_size)"
      ],
      "metadata": {
        "id": "fY8qRV2o2uFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(train_dl,invert=True)"
      ],
      "metadata": {
        "id": "kgkesCAd2wK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "device = get_default_device()"
      ],
      "metadata": {
        "id": "H-v7j6L32xFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "fa6KMYC32zpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassification(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "_4_dt7ZT211B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerModel(ImageClassification):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), \n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), \n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), \n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(256*28*28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 5))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "LyVLI-Ho24QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ],
      "metadata": {
        "id": "JyQtV6Cf2-pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(FlowerModel(), device)"
      ],
      "metadata": {
        "id": "eNgdgtyr26qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "9SQQjJ-53Dsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "try1 = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ],
      "metadata": {
        "id": "y48QHND23HAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = DeviceDataLoader(test_dl, device)\n",
        "evaluate(model, test_dl)"
      ],
      "metadata": {
        "id": "2LWH4XLX3JaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(try1)"
      ],
      "metadata": {
        "id": "fr26xFVt3KH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(try1)"
      ],
      "metadata": {
        "id": "CZpSzkz73MlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_ds[1]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', database.classes[label], ', Predicted:', predict_image(img, FlowerModel()))"
      ],
      "metadata": {
        "id": "dEKo5JZ93O8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerModelResnet50(FlowerClassification):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet50(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 5)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))"
      ],
      "metadata": {
        "id": "8REaqbzY3RRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "opt_func_1 = torch.optim.Adam\n",
        "lr_1 = 0.001"
      ],
      "metadata": {
        "id": "1colOGD73Ton"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_dl)"
      ],
      "metadata": {
        "id": "X-Bct7oo3WK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(try2):\n",
        "    accuracies = [x['val_acc'] for x in try2]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(try2)"
      ],
      "metadata": {
        "id": "29T8kPlW3YyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(try2):\n",
        "    train_losses = [x.get('train_loss') for x in try2]\n",
        "    val_losses = [x['val_loss'] for x in try2]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "plot_losses(try2)"
      ],
      "metadata": {
        "id": "Dc55dbIN3arq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_ds[70]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', database.classes[label], ', Predicted:', predict_image(img, FlowerModelResnet50()))"
      ],
      "metadata": {
        "id": "9fIqb1DN3dzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerModel18(FlowerClassification):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet18(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 5)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))"
      ],
      "metadata": {
        "id": "cG_Ff-at3i2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "R-ztQDat3kAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_dl)"
      ],
      "metadata": {
        "id": "6aWiehwO3mFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_ds[10]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', database.classes[label], ', Predicted:', predict_image(img, FlowerModel18()))"
      ],
      "metadata": {
        "id": "B3ahisv23oNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = DeviceDataLoader(test_dl, device)\n",
        "evaluate(model, test_dl)"
      ],
      "metadata": {
        "id": "LHnD6Tq53tNt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}